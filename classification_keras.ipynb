{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_data(n=30):\n",
    "    # Class 1 - samples generation\n",
    "    X1_1 = 1 + 4 * np.random.rand(n, 1)\n",
    "    X1_2 = 1 + 4 * np.random.rand(n, 1)\n",
    "    class1 = np.concatenate((X1_1, X1_2), axis=1)\n",
    "    Y1 = np.ones(n)\n",
    "\n",
    "    # Class 0 - samples generation\n",
    "    X0_1 = 3 + 4 * np.random.rand(n, 1)\n",
    "    X0_2 = 3 + 4 * np.random.rand(n, 1)\n",
    "    class0 = np.concatenate((X0_1, X0_2), axis=1)\n",
    "    Y0 = np.zeros(n)\n",
    "\n",
    "    X = np.concatenate((class1, class0))\n",
    "    Y = np.concatenate((Y1, Y0))\n",
    "\n",
    "    idx0 = [i for i, v in enumerate(Y) if v == 0]\n",
    "    idx1 = [i for i, v in enumerate(Y) if v == 1]\n",
    "\n",
    "    return X, Y, idx0, idx1\n",
    "\n",
    "X, Y, idx0, idx1 = generate_classification_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification model\n",
    "\n",
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "my_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "my_model.fit(X, Y, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification models\n",
    "\n",
    "## One hidden layer\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "## Two hidden layers\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "## Three hidden layers\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "## Compile all of the models\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Train for 500 epochs all of the models:\n",
    "history_1 = model_1.fit(X, Y, validation_split=0.2, epochs=100)\n",
    "history_2 = model_2.fit(X, Y, validation_split=0.2, epochs=100)\n",
    "history_3 = model_3.fit(X, Y, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_1.history['val_loss'], label='1-layer model', color='green')\n",
    "plt.plot(history_2.history['val_loss'], label='2-layer model', color='red')\n",
    "plt.plot(history_3.history['val_loss'], label='3-layer model', color='blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val_loss')\n",
    "plt.title(\"Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training best model\n",
    "\n",
    "best_model = tf.keras.Sequential([\n",
    "    model_2,\n",
    "])\n",
    "\n",
    "## Compile\n",
    "best_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Train for another 300 epochs\n",
    "best_history = best_model.fit(X, Y, validation_split=0.2, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_history.history['val_loss'], label='Best model learning continuation', color='green')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val_loss')\n",
    "plt.title(\"Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train best model on different learning rate\n",
    "big_lr_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "mid_lr_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "low_lr_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile all of the models\n",
    "big_lr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mid_lr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "low_lr_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Create early stopper callback\n",
    "earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=50)\n",
    "\n",
    "## Train for 300 epochs with early stopping\n",
    "big_lr_history = big_lr_model.fit(X, Y, validation_split=0.2, epochs=300, callbacks=[earlystopper])\n",
    "mid_lr_history = mid_lr_model.fit(X, Y, validation_split=0.2, epochs=300, callbacks=[earlystopper])\n",
    "low_lr_history = low_lr_model.fit(X, Y, validation_split=0.2, epochs=300, callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(big_lr_history.history['val_loss'], label='0.1 learning rate', color='green')\n",
    "plt.plot(mid_lr_history.history['val_loss'], label='0.01 learning rate', color='red')\n",
    "plt.plot(low_lr_history.history['val_loss'], label='0.001 learning rate', color='blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val_loss')\n",
    "plt.title(\"Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
